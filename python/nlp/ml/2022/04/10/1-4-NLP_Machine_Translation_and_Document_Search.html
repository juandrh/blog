<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>1.4- NLP: Machine Translation and Document Search | Juan del Río</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="1.4- NLP: Machine Translation and Document Search" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Procesamiento del lenguaje natural with Classification and Vector Spaces" />
<meta property="og:description" content="Procesamiento del lenguaje natural with Classification and Vector Spaces" />
<link rel="canonical" href="https://juandrh.github.io/blog/python/nlp/ml/2022/04/10/1-4-NLP_Machine_Translation_and_Document_Search.html" />
<meta property="og:url" content="https://juandrh.github.io/blog/python/nlp/ml/2022/04/10/1-4-NLP_Machine_Translation_and_Document_Search.html" />
<meta property="og:site_name" content="Juan del Río" />
<meta property="og:image" content="https://juandrh.github.io/blog/images/framework.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-04-10T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://juandrh.github.io/blog/python/nlp/ml/2022/04/10/1-4-NLP_Machine_Translation_and_Document_Search.html","@type":"BlogPosting","headline":"1.4- NLP: Machine Translation and Document Search","dateModified":"2022-04-10T00:00:00-05:00","datePublished":"2022-04-10T00:00:00-05:00","image":"https://juandrh.github.io/blog/images/framework.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://juandrh.github.io/blog/python/nlp/ml/2022/04/10/1-4-NLP_Machine_Translation_and_Document_Search.html"},"description":"Procesamiento del lenguaje natural with Classification and Vector Spaces","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://juandrh.github.io/blog/feed.xml" title="Juan del Río" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Juan del Río</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">1.4- NLP: Machine Translation and Document Search</h1><p class="page-description">Procesamiento del lenguaje natural with Classification and Vector Spaces</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-04-10T00:00:00-05:00" itemprop="datePublished">
        Apr 10, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      25 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#NLP">NLP</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#ML">ML</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/juandrh/blog/tree/master/_notebooks/2022-04-10-1-4-NLP_Machine_Translation_and_Document_Search.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/juandrh/blog/master?filepath=_notebooks%2F2022-04-10-1-4-NLP_Machine_Translation_and_Document_Search.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/juandrh/blog/blob/master/_notebooks/2022-04-10-1-4-NLP_Machine_Translation_and_Document_Search.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Transforming-word-vectors">Transforming word vectors </a></li>
<li class="toc-entry toc-h1"><a href="#K-nearest-neighbors">K-nearest neighbors </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Hashing">Hashing </a></li>
<li class="toc-entry toc-h2"><a href="#locality-sensitive-hashing">locality sensitive hashing </a></li>
<li class="toc-entry toc-h2"><a href="#Multiple-Planes">Multiple Planes </a></li>
<li class="toc-entry toc-h2"><a href="#Random-Planes">Random Planes </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Approximate-nearest-neighbors">Approximate nearest neighbors </a></li>
<li class="toc-entry toc-h1"><a href="#Naive-Machine-Translation">Naive Machine Translation </a>
<ul>
<li class="toc-entry toc-h2"><a href="#The-word-embeddings-data-for-English-and-French-words">The word embeddings data for English and French words </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Generate-embedding-and-transform-matrices">Generate embedding and transform matrices </a></li>
<li class="toc-entry toc-h3"><a href="#Translations">Translations </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Translation-as-linear-transformation-of-embeddings-(R)">Translation as linear transformation of embeddings (R) </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Computing-the-gradient-of-loss-in-respect-to-transform-matrix-R">Computing the gradient of loss in respect to transform matrix R </a></li>
<li class="toc-entry toc-h3"><a href="#Finding-the-optimal-R-with-gradient-descent-algorithm">Finding the optimal R with gradient descent algorithm </a></li>
<li class="toc-entry toc-h3"><a href="#Calculate-transformation-matrix-R">Calculate transformation matrix R </a></li>
<li class="toc-entry toc-h3"><a href="#Testing-the-translation">Testing the translation </a>
<ul>
<li class="toc-entry toc-h4"><a href="#k-Nearest-neighbors-algorithm">k-Nearest neighbors algorithm </a></li>
<li class="toc-entry toc-h4"><a href="#Searching-for-the-translation-embedding">Searching for the translation embedding </a></li>
<li class="toc-entry toc-h4"><a href="#Test-your-translation-and-compute-its-accuracy">Test your translation and compute its accuracy </a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#LSH-(locality-sensitive-hashing)-and-document-search">LSH (locality sensitive hashing) and document search </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Getting-the-document-embeddings">Getting the document embeddings </a></li>
<li class="toc-entry toc-h2"><a href="#Store-all-document-vectors-into-a-dictionary">Store all document vectors into a dictionary </a></li>
<li class="toc-entry toc-h2"><a href="#Looking-up-the-tweets">Looking up the tweets </a></li>
<li class="toc-entry toc-h2"><a href="#Finding-the-most-similar-tweets-with-LSH">Finding the most similar tweets with LSH </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Choosing-the-number-of-planes">Choosing the number of planes </a></li>
<li class="toc-entry toc-h3"><a href="#Getting-the-hash-number-for-a-vector">Getting the hash number for a vector </a></li>
<li class="toc-entry toc-h3"><a href="#Creating-a-hash-table">Creating a hash table </a></li>
<li class="toc-entry toc-h3"><a href="#Creating-all-hash-tables">Creating all hash tables </a></li>
<li class="toc-entry toc-h3"><a href="#Approximate-K-NN">Approximate K-NN </a></li>
</ul>
</li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-04-10-1-4-NLP_Machine_Translation_and_Document_Search.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fuentes:
<a href="https://www.coursera.org/specializations/natural-language-processing">DeepLearning.AI: Procesamiento de lenguaje natural. Programa especializado en Coursera</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Transforming-word-vectors">
<a class="anchor" href="#Transforming-word-vectors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transforming word vectors<a class="anchor-link" href="#Transforming-word-vectors"> </a>
</h1>
<ul>
<li>From languaje X to languaje Y -&gt; X R =Y</li>
<li>Learn R:</li>
<li><img src="images/nlp027.png" alt=""></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/images/nlp028.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="K-nearest-neighbors">
<a class="anchor" href="#K-nearest-neighbors" aria-hidden="true"><span class="octicon octicon-link"></span></a>K-nearest neighbors<a class="anchor-link" href="#K-nearest-neighbors"> </a>
</h1>
<p>we need to find the most similar vectors to your output.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hashing">
<a class="anchor" href="#Hashing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hashing<a class="anchor-link" href="#Hashing"> </a>
</h2>
<ul>
<li>
<strong>hash_function</strong> = takes data of arbitrary sizes and maps it to a fixed value.</li>
<li>you don't have to compare it to all the other examples, you can just compare it to all the values in the same hash_bucket that input has been hashed to. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/images/nlp029.png" alt="">
<img src="/blog/images/copied_from_nb/images/nlp030.png" alt=""></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">basic_hash_table</span><span class="p">(</span><span class="n">value_l</span><span class="p">,</span> <span class="n">n_buckets</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">hash_function</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">n_buckets</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">%</span> <span class="n">n_buckets</span>
    
    <span class="n">hash_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_buckets</span><span class="p">)}</span> <span class="c1"># Initialize all the buckets in the hash table as empty lists</span>

    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">value_l</span><span class="p">:</span>
        <span class="n">hash_value</span> <span class="o">=</span> <span class="n">hash_function</span><span class="p">(</span><span class="n">value</span><span class="p">,</span><span class="n">n_buckets</span><span class="p">)</span> <span class="c1"># Get the hash key for the given value</span>
        <span class="n">hash_table</span><span class="p">[</span><span class="n">hash_value</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="c1"># Add the element to the corresponding bucket</span>
    
    <span class="k">return</span> <span class="n">hash_table</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">value_l</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">97</span><span class="p">]</span> <span class="c1"># Set of values to hash</span>
<span class="n">hash_table_example</span> <span class="o">=</span> <span class="n">basic_hash_table</span><span class="p">(</span><span class="n">value_l</span><span class="p">,</span> <span class="n">n_buckets</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">hash_table_example</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{   0: [100, 10],
    1: [],
    2: [],
    3: [],
    4: [14],
    5: [],
    6: [],
    7: [17, 97],
    8: [],
    9: []}
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="locality-sensitive-hashing">
<a class="anchor" href="#locality-sensitive-hashing" aria-hidden="true"><span class="octicon octicon-link"></span></a>locality sensitive hashing<a class="anchor-link" href="#locality-sensitive-hashing"> </a>
</h2>
<p>technique that allows you to hash similar inputs into the same buckets with high probability.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/images/nlp031.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Multiple-Planes">
<a class="anchor" href="#Multiple-Planes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple Planes<a class="anchor-link" href="#Multiple-Planes"> </a>
</h2>
<p>To get a single hash value.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/images/nlp032.png" alt=""></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>   <span class="c1"># library for array and matrix manipulation</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pprint</span>                     <span class="c1"># utilities for console printing </span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>   <span class="c1"># visualization library</span>
<span class="n">pp</span> <span class="o">=</span> <span class="n">pprint</span><span class="o">.</span><span class="n">PrettyPrinter</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Instantiate a pretty printer</span>
<span class="kn">import</span> <span class="nn">pdb</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="c1">#import gensim</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="c1">#from gensim.models import KeyedVectors</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span><span class="p">,</span> <span class="n">twitter_samples</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">TweetTokenizer</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">getcwd</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">filePath</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">getcwd</span><span class="p">()</span><span class="si">}</span><span class="s2">/tmp2/"</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">filePath</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_dict</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    This function returns the english to french dictionary given a file where the each column corresponds to a word.</span>
<span class="sd">    Check out the files this function takes in your workspace.</span>
<span class="sd">    """</span>
    <span class="n">my_file</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
    <span class="n">etof</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># the english to french dictionary to be returned</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">my_file</span><span class="p">)):</span>
        <span class="c1"># indexing into the rows.</span>
        <span class="n">en</span> <span class="o">=</span> <span class="n">my_file</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">fr</span> <span class="o">=</span> <span class="n">my_file</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">etof</span><span class="p">[</span><span class="n">en</span><span class="p">]</span> <span class="o">=</span> <span class="n">fr</span>

    <span class="k">return</span> <span class="n">etof</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Input:</span>
<span class="sd">        A: a numpy array which corresponds to a word vector</span>
<span class="sd">        B: A numpy array which corresponds to a word vector</span>
<span class="sd">    Output:</span>
<span class="sd">        cos: numerical number representing the cosine similarity between A and B.</span>
<span class="sd">    '''</span>
    <span class="c1"># you have to set this variable to the true label.</span>
    <span class="n">cos</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10</span>
    <span class="n">dot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
    <span class="n">norma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">normb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="n">cos</span> <span class="o">=</span> <span class="n">dot</span> <span class="o">/</span> <span class="p">(</span><span class="n">norma</span> <span class="o">*</span> <span class="n">normb</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cos</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_tweet</span><span class="p">(</span><span class="n">tweet</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Input:</span>
<span class="sd">        tweet: a string containing a tweet</span>
<span class="sd">    Output:</span>
<span class="sd">        tweets_clean: a list of words containing the processed tweet</span>

<span class="sd">    '''</span>
    <span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
    <span class="n">stopwords_english</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">'english'</span><span class="p">)</span>
    <span class="c1"># remove stock market tickers like $GE</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\$\w*'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="c1"># remove old style retweet text "RT"</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'^RT[\s]+'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="c1"># remove hyperlinks</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'https?:\/\/.*[\r\n]*'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="c1"># remove hashtags</span>
    <span class="c1"># only removing the hash # sign from the word</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'#'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="c1"># tokenize tweets</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">preserve_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">tweet_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>

    <span class="n">tweets_clean</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet_tokens</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords_english</span> <span class="ow">and</span>  <span class="c1"># remove stopwords</span>
            <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">):</span>  <span class="c1"># remove punctuation</span>
            <span class="c1"># tweets_clean.append(word)</span>
            <span class="n">stem_word</span> <span class="o">=</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>  <span class="c1"># stemming word</span>
            <span class="n">tweets_clean</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stem_word</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tweets_clean</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plot_vectors</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">'k'</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="s1">'m'</span><span class="p">,</span> <span class="s1">'c'</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fname</span><span class="o">=</span><span class="s1">'image.svg'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">scale_units</span> <span class="o">=</span> <span class="s1">'x'</span>
    <span class="n">x_dir</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_dir</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vectors</span><span class="p">):</span>
        <span class="n">x_dir</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">y_dir</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">ax</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span>
      
    <span class="k">if</span> <span class="n">axes</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x_axis</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_dir</span><span class="p">))</span>
        <span class="n">y_axis</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_dir</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_axis</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_axis</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">ax2</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">x_axis</span><span class="p">,</span> <span class="o">-</span><span class="n">y_axis</span><span class="p">,</span> <span class="n">y_axis</span><span class="p">])</span>
        
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vectors</span><span class="p">):</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.05</span> <span class="o">*</span> <span class="n">x_axis</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mf">0.05</span> <span class="o">*</span> <span class="n">y_axis</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ec</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">ax</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]])</span>  <span class="c1"># Define a single plane. You may change the direction</span>

<span class="c1"># Get a new plane perpendicular to P. We use a rotation matrix</span>
<span class="n">PT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">P</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>  

<span class="n">fig</span><span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span> <span class="c1"># Create a plot with custom size</span>

<span class="n">plot_vectors</span><span class="p">([</span><span class="n">P</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">'b'</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span> <span class="c1"># Plot the plane P as a vector</span>

<span class="c1"># Plot the plane P as a 2 vectors. </span>
<span class="c1"># We scale by 2 just to get the arrows outside the current box</span>
<span class="n">plot_vectors</span><span class="p">([</span><span class="n">PT</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">PT</span> <span class="o">*</span> <span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">'k'</span><span class="p">,</span> <span class="s1">'k'</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>

<span class="c1"># Plot 20 random points. </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">):</span>
        <span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="c1"># Get a pair of random numbers between -4 and 4 </span>
        <span class="n">side_of_plane</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">v1</span><span class="o">.</span><span class="n">T</span><span class="p">))</span> <span class="c1"># Get the sign of the dot product with P</span>
        <span class="c1"># Color the points depending on the sign of the result of np.dot(P, point.T)</span>
        <span class="k">if</span> <span class="n">side_of_plane</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">v1</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">v1</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="s1">'bo'</span><span class="p">)</span> <span class="c1"># Plot a blue point</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">v1</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">v1</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="s1">'ro'</span><span class="p">)</span> <span class="c1"># Plot a red point</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">side_of_plane_scalar</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>  <span class="c1"># scalar</span>
    <span class="n">dotproduct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># Get the dot product P * v'</span>
    <span class="n">sign_of_dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">dotproduct</span><span class="p">)</span> <span class="c1"># The sign of the elements of the dotproduct matrix </span>
    <span class="n">sign_of_dot_product_scalar</span> <span class="o">=</span> <span class="n">sign_of_dot_product</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="c1"># The value of the first item</span>
    <span class="k">return</span> <span class="n">sign_of_dot_product_scalar</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">hash_multi_plane</span><span class="p">(</span><span class="n">P_l</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="n">hash_value</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">P</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">P_l</span><span class="p">):</span>
        <span class="n">sign</span> <span class="o">=</span> <span class="n">side_of_plane_scalar</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
        <span class="n">hash_i</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">sign</span> <span class="o">&gt;=</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">hash_value</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span> <span class="o">*</span> <span class="n">hash_i</span>
    <span class="k">return</span> <span class="n">hash_value</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">P1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>   <span class="c1"># First plane 2D</span>
<span class="n">P2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>  <span class="c1"># Second plane 2D</span>
<span class="n">P3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span> <span class="c1"># Third plane 2D</span>
<span class="n">P_l</span> <span class="o">=</span> <span class="p">[</span><span class="n">P1</span><span class="p">,</span> <span class="n">P2</span><span class="p">,</span> <span class="n">P3</span><span class="p">]</span>  <span class="c1"># List of arrays. It is the multi plane</span>

<span class="c1"># Vector to search</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hash_multi_plane</span><span class="p">(</span><span class="n">P_l</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="c1"># Find the number of the plane that containes this value</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>3</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">side_of_plane_matrix</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="n">dotproduct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">sign_of_dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">dotproduct</span><span class="p">)</span> <span class="c1"># Get a boolean value telling if the value in the cell is positive or negative</span>
    <span class="k">return</span> <span class="n">sign_of_dot_product</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Random-Planes">
<a class="anchor" href="#Random-Planes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random Planes<a class="anchor-link" href="#Random-Planes"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">num_dimensions</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># is 300 in assignment</span>
<span class="n">num_planes</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># is 10 in assignment</span>
<span class="n">random_planes_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
                       <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_planes</span><span class="p">,</span>
                             <span class="n">num_dimensions</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">random_planes_matrix</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[ 1.62434536 -0.61175641]
 [-0.52817175 -1.07296862]
 [ 0.86540763 -2.3015387 ]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sides_l</span> <span class="o">=</span> <span class="n">side_of_plane_matrix</span><span class="p">(</span><span class="n">random_planes_matrix</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<span class="n">sides_l</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[ 1.],
       [-1.],
       [-1.]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Approximate-nearest-neighbors">
<a class="anchor" href="#Approximate-nearest-neighbors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Approximate nearest neighbors<a class="anchor-link" href="#Approximate-nearest-neighbors"> </a>
</h1>
<p>trades off accuracy for efficiency</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Naive-Machine-Translation">
<a class="anchor" href="#Naive-Machine-Translation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Naive Machine Translation<a class="anchor-link" href="#Naive-Machine-Translation"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-word-embeddings-data-for-English-and-French-words">
<a class="anchor" href="#The-word-embeddings-data-for-English-and-French-words" aria-hidden="true"><span class="octicon octicon-link"></span></a>The word embeddings data for English and French words<a class="anchor-link" href="#The-word-embeddings-data-for-English-and-French-words"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">en_embeddings_subset</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">"./data/en_embeddings.p"</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">))</span>
<span class="n">fr_embeddings_subset</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">"./data/fr_embeddings.p"</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">en_fr_train</span> <span class="o">=</span> <span class="n">get_dict</span><span class="p">(</span><span class="s1">'./data/en-fr.train.txt'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'The length of the English to French training dictionary is'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">en_fr_train</span><span class="p">))</span>
<span class="n">en_fr_test</span> <span class="o">=</span> <span class="n">get_dict</span><span class="p">(</span><span class="s1">'./data/en-fr.test.txt'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'The length of the English to French test dictionary is'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">en_fr_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>The length of the English to French training dictionary is 5000
The length of the English to French test dictionary is 1500
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Generate-embedding-and-transform-matrices">
<a class="anchor" href="#Generate-embedding-and-transform-matrices" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generate embedding and transform matrices<a class="anchor-link" href="#Generate-embedding-and-transform-matrices"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_matrices</span><span class="p">(</span><span class="n">en_fr</span><span class="p">,</span> <span class="n">french_vecs</span><span class="p">,</span> <span class="n">english_vecs</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Input:</span>
<span class="sd">        en_fr: English to French dictionary</span>
<span class="sd">        french_vecs: French words to their corresponding word embeddings.</span>
<span class="sd">        english_vecs: English words to their corresponding word embeddings.</span>
<span class="sd">    Output: </span>
<span class="sd">        X: a matrix where the columns are the English embeddings.</span>
<span class="sd">        Y: a matrix where the columns correspong to the French embeddings.</span>
<span class="sd">        R: the projection matrix that minimizes the F norm ||X R -Y||^2.</span>
<span class="sd">    """</span>    
    <span class="c1"># X_l and Y_l are lists of the english and french word embeddings</span>
    <span class="n">X_l</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">Y_l</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>    
    <span class="c1"># get the english words (the keys in the dictionary) and store in a set()</span>
    <span class="n">english_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">english_vecs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>  
    <span class="c1"># get the french words (keys in the dictionary) and store in a set()</span>
    <span class="n">french_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">french_vecs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>    
    <span class="c1"># store the french words that are part of the english-french dictionary (these are the values of the dictionary)</span>
    <span class="n">french_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">en_fr</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    
    <span class="c1"># loop through all english, french word pairs in the english french dictionary</span>
    <span class="k">for</span> <span class="n">en_word</span><span class="p">,</span> <span class="n">fr_word</span> <span class="ow">in</span> <span class="n">en_fr</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># check that the french word has an embedding and that the english word has an embedding</span>
        <span class="k">if</span> <span class="n">fr_word</span> <span class="ow">in</span> <span class="n">french_set</span> <span class="ow">and</span> <span class="n">en_word</span> <span class="ow">in</span> <span class="n">english_set</span><span class="p">:</span>
            <span class="c1"># get the english embedding</span>
            <span class="n">en_vec</span> <span class="o">=</span> <span class="n">english_vecs</span><span class="p">[</span><span class="n">en_word</span><span class="p">]</span>
            <span class="c1"># get the french embedding</span>
            <span class="n">fr_vec</span> <span class="o">=</span> <span class="n">french_vecs</span><span class="p">[</span><span class="n">fr_word</span><span class="p">]</span>
            <span class="c1"># add the english embedding to the list</span>
            <span class="n">X_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">en_vec</span><span class="p">)</span>
            <span class="c1"># add the french embedding to the list</span>
            <span class="n">Y_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fr_vec</span><span class="p">)</span>
    <span class="c1"># stack the vectors of X_l into a matrix X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_l</span><span class="p">)</span>
    <span class="c1"># stack the vectors of Y_l into a matrix Y</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y_l</span><span class="p">)</span> 
    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span> <span class="o">=</span> <span class="n">get_matrices</span><span class="p">(</span>
    <span class="n">en_fr_train</span><span class="p">,</span> <span class="n">fr_embeddings_subset</span><span class="p">,</span> <span class="n">en_embeddings_subset</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Translations">
<a class="anchor" href="#Translations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Translations<a class="anchor-link" href="#Translations"> </a>
</h3>
<h4 id="Translation-as-linear-transformation-of-embeddings-(R)">
<a class="anchor" href="#Translation-as-linear-transformation-of-embeddings-(R)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Translation as linear transformation of embeddings (R)<a class="anchor-link" href="#Translation-as-linear-transformation-of-embeddings-(R)"> </a>
</h4>
<p>Find a matrix R that minimizes the following equation:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/images/nlp033.png" alt=""></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">R</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Inputs: </span>
<span class="sd">        X: a matrix of dimension (m,n) where the columns are the English embeddings.</span>
<span class="sd">        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.</span>
<span class="sd">        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.</span>
<span class="sd">    Outputs:</span>
<span class="sd">        L: a matrix of dimension (m,n) - the value of the loss function for given X, Y and R.</span>
<span class="sd">    '''</span>
    <span class="c1"># m is the number of rows in X</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>   
    <span class="c1"># diff is XR - Y    </span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">R</span><span class="p">)</span><span class="o">-</span><span class="n">Y</span>

    <span class="c1"># diff_squared is the element-wise square of the difference    </span>
    <span class="n">diff_squared</span> <span class="o">=</span> <span class="n">diff</span><span class="o">**</span><span class="mi">2</span>
    <span class="c1"># sum_diff_squared is the sum of the squared elements</span>
    <span class="n">sum_diff_squared</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diff_squared</span><span class="p">)</span>

    <span class="c1"># loss i the sum_diff_squard divided by the number of examples (m)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">sum_diff_squared</span> <span class="o">/</span> <span class="n">m</span>
    
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected loss for an experiment with random matrices: </span><span class="si">{</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">R</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span> <span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Expected loss for an experiment with random matrices: 8.1866
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Computing-the-gradient-of-loss-in-respect-to-transform-matrix-R">
<a class="anchor" href="#Computing-the-gradient-of-loss-in-respect-to-transform-matrix-R" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computing the gradient of loss in respect to transform matrix R<a class="anchor-link" href="#Computing-the-gradient-of-loss-in-respect-to-transform-matrix-R"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/images/nlp034.png" alt=""></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">compute_gradient</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">R</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Inputs: </span>
<span class="sd">        X: a matrix of dimension (m,n) where the columns are the English embeddings.</span>
<span class="sd">        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.</span>
<span class="sd">        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.</span>
<span class="sd">    Outputs:</span>
<span class="sd">        g: a scalar value - gradient of the loss function L for given X, Y and R.</span>
<span class="sd">    '''</span>   
    <span class="c1"># m is the number of rows in X</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># gradient is X^T(XR - Y) * 2/m    </span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">R</span><span class="p">)</span><span class="o">-</span><span class="n">Y</span><span class="p">))</span><span class="o">*</span><span class="mi">2</span><span class="o">/</span><span class="n">m</span>

    <span class="k">return</span> <span class="n">gradient</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="n">compute_gradient</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">R</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First row of the gradient matrix: </span><span class="si">{</span><span class="n">gradient</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>First row of the gradient matrix: [1.3498175  1.11264981 0.69626762 0.98468499 1.33828969]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Finding-the-optimal-R-with-gradient-descent-algorithm">
<a class="anchor" href="#Finding-the-optimal-R-with-gradient-descent-algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finding the optimal R with gradient descent algorithm<a class="anchor-link" href="#Finding-the-optimal-R-with-gradient-descent-algorithm"> </a>
</h3>
<ul>
<li>Calculate gradient  g  of the loss with respect to the matrix  R .</li>
<li>Update  R  with the formula:  Rnew=Rold−αg , where  α  is the learning rate, which is a scalar.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">align_embeddings</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">train_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0003</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compute_loss</span><span class="o">=</span><span class="n">compute_loss</span><span class="p">,</span> <span class="n">compute_gradient</span><span class="o">=</span><span class="n">compute_gradient</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Inputs:</span>
<span class="sd">        X: a matrix of dimension (m,n) where the columns are the English embeddings.</span>
<span class="sd">        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.</span>
<span class="sd">        train_steps: positive int - describes how many steps will gradient descent algorithm do.</span>
<span class="sd">        learning_rate: positive float - describes how big steps will  gradient descent algorithm do.</span>
<span class="sd">    Outputs:</span>
<span class="sd">        R: a matrix of dimension (n,n) - the projection matrix that minimizes the F norm ||X R -Y||^2</span>
<span class="sd">    '''</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">129</span><span class="p">)</span>

    <span class="c1"># the number of columns in X is the number of dimensions for a word vector (e.g. 300)</span>
    <span class="c1"># R is a square matrix with length equal to the number of dimensions in th  word embedding</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">train_steps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"loss at iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> is: </span><span class="si">{</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">R</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># use the function that you defined to compute the gradient</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">compute_gradient</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">R</span><span class="p">)</span>

        <span class="c1"># update R by subtracting the learning rate times gradient</span>
        <span class="n">R</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span>

    <span class="k">return</span> <span class="n">R</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">129</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">align_embeddings</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>loss at iteration 0 is: 3.7242
loss at iteration 25 is: 3.6283
loss at iteration 50 is: 3.5350
loss at iteration 75 is: 3.4442
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Calculate-transformation-matrix-R">
<a class="anchor" href="#Calculate-transformation-matrix-R" aria-hidden="true"><span class="octicon octicon-link"></span></a>Calculate transformation matrix R<a class="anchor-link" href="#Calculate-transformation-matrix-R"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">R_train</span> <span class="o">=</span> <span class="n">align_embeddings</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">train_steps</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>loss at iteration 0 is: 963.0146
loss at iteration 25 is: 97.8292
loss at iteration 50 is: 26.8329
loss at iteration 75 is: 9.7893
loss at iteration 100 is: 4.3776
loss at iteration 125 is: 2.3281
loss at iteration 150 is: 1.4480
loss at iteration 175 is: 1.0338
loss at iteration 200 is: 0.8251
loss at iteration 225 is: 0.7145
loss at iteration 250 is: 0.6534
loss at iteration 275 is: 0.6185
loss at iteration 300 is: 0.5981
loss at iteration 325 is: 0.5858
loss at iteration 350 is: 0.5782
loss at iteration 375 is: 0.5735
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Testing-the-translation">
<a class="anchor" href="#Testing-the-translation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Testing the translation<a class="anchor-link" href="#Testing-the-translation"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="k-Nearest-neighbors-algorithm">
<a class="anchor" href="#k-Nearest-neighbors-algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>k-Nearest neighbors algorithm<a class="anchor-link" href="#k-Nearest-neighbors-algorithm"> </a>
</h4>
<ul>
<li>k-NN is a method which takes a vector as input and finds the other vectors in the dataset that are closest to it.</li>
<li>The 'k' is the number of "nearest neighbors" to find (e.g. k=2 finds the closest two neighbors).</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Searching-for-the-translation-embedding">
<a class="anchor" href="#Searching-for-the-translation-embedding" aria-hidden="true"><span class="octicon octicon-link"></span></a>Searching for the translation embedding<a class="anchor-link" href="#Searching-for-the-translation-embedding"> </a>
</h4>
<p>Since we're approximating the translation function from English to French embeddings by a linear transformation matrix  R , most of the time we won't get the exact embedding of a French word when we transform embedding  e  of some particular English word into the French embedding space.</p>
<p>This is where  k -NN becomes really useful! By using  1 -NN with  eR  as input, we can search for an embedding  f  (as a row) in the matrix  Y  which is the closest to the transformed vector  eR</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">nearest_neighbor</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cosine_similarity</span><span class="o">=</span><span class="n">cosine_similarity</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Input:</span>
<span class="sd">      - v, the vector you are going find the nearest neighbor for</span>
<span class="sd">      - candidates: a set of vectors where we will find the neighbors</span>
<span class="sd">      - k: top k nearest neighbors to find</span>
<span class="sd">    Output:</span>
<span class="sd">      - k_idx: the indices of the top k closest vectors in sorted form</span>
<span class="sd">    """</span>
    <span class="n">similarity_l</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># for each candidate vector...</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
        <span class="c1"># get the cosine similarity</span>
        <span class="n">cos_similarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">row</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">row</span><span class="p">))</span>
        
        <span class="c1"># append the similarity to the list</span>
        <span class="n">similarity_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cos_similarity</span><span class="p">)</span>

    <span class="c1"># sort the similarity list and get the indices of the sorted list    </span>
    <span class="n">sorted_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">similarity_l</span><span class="p">)</span>
    
    <span class="c1"># Reverse the order of the sorted_ids array</span>
    <span class="n">sorted_ids</span> <span class="o">=</span> <span class="n">sorted_ids</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># get the indices of the k most similar candidate vectors</span>
    <span class="n">k_idx</span> <span class="o">=</span> <span class="n">sorted_ids</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span>
    <span class="c1">### END CODE HERE ###</span>
    <span class="k">return</span> <span class="n">k_idx</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">candidates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">candidates</span><span class="p">[</span><span class="n">nearest_neighbor</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="mi">3</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[2 0 1]
 [1 0 5]
 [9 9 9]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Test-your-translation-and-compute-its-accuracy">
<a class="anchor" href="#Test-your-translation-and-compute-its-accuracy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test your translation and compute its accuracy<a class="anchor-link" href="#Test-your-translation-and-compute-its-accuracy"> </a>
</h4>
<p>Accuracy = total correct / total</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_vocabulary</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">nearest_neighbor</span><span class="o">=</span><span class="n">nearest_neighbor</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Input:</span>
<span class="sd">        X: a matrix where the columns are the English embeddings.</span>
<span class="sd">        Y: a matrix where the columns correspong to the French embeddings.</span>
<span class="sd">        R: the transform matrix which translates word embeddings from</span>
<span class="sd">        English to French word vector space.</span>
<span class="sd">    Output:</span>
<span class="sd">        accuracy: for the English to French capitals</span>
<span class="sd">    '''</span>
    <span class="c1"># The prediction is X times R</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">R</span><span class="p">)</span>    
    <span class="c1"># initialize the number correct to zero</span>
    <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># loop through each row in pred (each transformed embedding)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)):</span>
        <span class="c1"># get the index of the nearest neighbor of pred at row 'i'; also pass in the candidates in Y</span>
        <span class="n">pred_idx</span> <span class="o">=</span> <span class="n">nearest_neighbor</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">Y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cosine_similarity</span><span class="o">=</span><span class="n">cosine_similarity</span><span class="p">)</span>

        <span class="c1"># if the index of the nearest neighbor equals the row of i... \</span>
        <span class="k">if</span> <span class="n">pred_idx</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
            <span class="c1"># increment the number correct by 1.</span>
            <span class="n">num_correct</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># accuracy is the number correct divided by the number of rows in 'pred' (also number of rows in X)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">num_correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span> <span class="o">=</span> <span class="n">get_matrices</span><span class="p">(</span><span class="n">en_fr_test</span><span class="p">,</span> <span class="n">fr_embeddings_subset</span><span class="p">,</span> <span class="n">en_embeddings_subset</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">test_vocabulary</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">,</span> <span class="n">R_train</span><span class="p">)</span>  <span class="c1"># this might take a minute or two</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"accuracy on test set is </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>accuracy on test set is 0.557
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="LSH-(locality-sensitive-hashing)-and-document-search">
<a class="anchor" href="#LSH-(locality-sensitive-hashing)-and-document-search" aria-hidden="true"><span class="octicon octicon-link"></span></a>LSH (locality sensitive hashing) and document search<a class="anchor-link" href="#LSH-(locality-sensitive-hashing)-and-document-search"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_positive_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s1">'positive_tweets.json'</span><span class="p">)</span>
<span class="n">all_negative_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s1">'negative_tweets.json'</span><span class="p">)</span>
<span class="n">all_tweets</span> <span class="o">=</span> <span class="n">all_positive_tweets</span> <span class="o">+</span> <span class="n">all_negative_tweets</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-the-document-embeddings">
<a class="anchor" href="#Getting-the-document-embeddings" aria-hidden="true"><span class="octicon octicon-link"></span></a>Getting the document embeddings<a class="anchor-link" href="#Getting-the-document-embeddings"> </a>
</h2>
<p><strong>Bag-of-words (BOW)</strong> document models: Text documents are sequences of words.</p>
<ul>
<li>The ordering of words makes a difference. For example, sentences "Apple pie is better than pepperoni pizza." and "Pepperoni pizza is better than apple pie" have opposite meanings due to the word ordering.</li>
<li>However, for some applications, ignoring the order of words can allow us to train an efficient and still effective model. This approach is called Bag-of-words document model.
<strong>Document embeddings</strong>
</li>
<li>Document embedding is created by summing up the embeddings of all words in the document.</li>
<li>If we don't know the embedding of some word, we can ignore that word.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_document_embedding</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">en_embeddings</span><span class="p">,</span> <span class="n">process_tweet</span><span class="o">=</span><span class="n">process_tweet</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Input:</span>
<span class="sd">        - tweet: a string</span>
<span class="sd">        - en_embeddings: a dictionary of word embeddings</span>
<span class="sd">    Output:</span>
<span class="sd">        - doc_embedding: sum of all word embeddings in the tweet</span>
<span class="sd">    '''</span>
    <span class="n">doc_embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>   
    <span class="c1"># process the document into a list of words (process the tweet)</span>
    <span class="n">processed_doc</span> <span class="o">=</span> <span class="n">process_tweet</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">processed_doc</span><span class="p">:</span>
        <span class="c1"># add the word embedding to the running total for the document embedding        </span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">en_embeddings</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">doc_embedding</span> <span class="o">+=</span> <span class="n">en_embeddings</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">doc_embedding</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">custom_tweet</span> <span class="o">=</span> <span class="s2">"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np"</span>
<span class="n">tweet_embedding</span> <span class="o">=</span> <span class="n">get_document_embedding</span><span class="p">(</span><span class="n">custom_tweet</span><span class="p">,</span> <span class="n">en_embeddings_subset</span><span class="p">)</span>
<span class="n">tweet_embedding</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([-0.00268555, -0.15378189, -0.55761719, -0.07216644, -0.32263184])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Store-all-document-vectors-into-a-dictionary">
<a class="anchor" href="#Store-all-document-vectors-into-a-dictionary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Store all document vectors into a dictionary<a class="anchor-link" href="#Store-all-document-vectors-into-a-dictionary"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_document_vecs</span><span class="p">(</span><span class="n">all_docs</span><span class="p">,</span> <span class="n">en_embeddings</span><span class="p">,</span> <span class="n">get_document_embedding</span><span class="o">=</span><span class="n">get_document_embedding</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Input:</span>
<span class="sd">        - all_docs: list of strings - all tweets in our dataset.</span>
<span class="sd">        - en_embeddings: dictionary with words as the keys and their embeddings as the values.</span>
<span class="sd">    Output:</span>
<span class="sd">        - document_vec_matrix: matrix of tweet embeddings.</span>
<span class="sd">        - ind2Doc_dict: dictionary with indices of tweets in vecs as keys and their embeddings as the values.</span>
<span class="sd">    '''</span>
    <span class="c1"># the dictionary's key is an index (integer) that identifies a specific tweet</span>
    <span class="c1"># the value is the document embedding for that document</span>
    <span class="n">ind2Doc_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># this is list that will store the document vectors</span>
    <span class="n">document_vec_l</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_docs</span><span class="p">):</span>

        <span class="c1"># get the document embedding of the tweet</span>
        <span class="n">doc_embedding</span> <span class="o">=</span> <span class="n">get_document_embedding</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">en_embeddings</span><span class="p">,</span> <span class="n">process_tweet</span><span class="o">=</span><span class="n">process_tweet</span><span class="p">)</span>

        <span class="c1"># save the document embedding into the ind2Tweet dictionary at index i</span>
        <span class="n">ind2Doc_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">doc_embedding</span>

        <span class="c1"># append the document embedding to the list of document vectors</span>
        <span class="n">document_vec_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc_embedding</span><span class="p">)</span>

    <span class="c1"># convert the list of document vectors into a 2D array (each row is a document vector)</span>
    <span class="n">document_vec_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">document_vec_l</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">document_vec_matrix</span><span class="p">,</span> <span class="n">ind2Doc_dict</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">document_vecs</span><span class="p">,</span> <span class="n">ind2Tweet</span> <span class="o">=</span> <span class="n">get_document_vecs</span><span class="p">(</span><span class="n">all_tweets</span><span class="p">,</span> <span class="n">en_embeddings_subset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"length of dictionary </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ind2Tweet</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"shape of document_vecs </span><span class="si">{</span><span class="n">document_vecs</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>length of dictionary 10000
shape of document_vecs (10000, 300)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Looking-up-the-tweets">
<a class="anchor" href="#Looking-up-the-tweets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Looking up the tweets<a class="anchor-link" href="#Looking-up-the-tweets"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">my_tweet</span> <span class="o">=</span> <span class="s1">'i am sad'</span>
<span class="n">process_tweet</span><span class="p">(</span><span class="n">my_tweet</span><span class="p">)</span>
<span class="n">tweet_embedding</span> <span class="o">=</span> <span class="n">get_document_embedding</span><span class="p">(</span><span class="n">my_tweet</span><span class="p">,</span> <span class="n">en_embeddings_subset</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># this implementation is vectorized...</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">document_vecs</span><span class="p">,</span> <span class="n">tweet_embedding</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">all_tweets</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>@zoeeylim sad sad sad kid :( it's ok I help you watch the match HAHAHAHAHA
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Finding-the-most-similar-tweets-with-LSH">
<a class="anchor" href="#Finding-the-most-similar-tweets-with-LSH" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finding the most similar tweets with LSH<a class="anchor-link" href="#Finding-the-most-similar-tweets-with-LSH"> </a>
</h2>
<p>Instead of looking at all 10,000 vectors, you can just search a subset to find its nearest neighbors.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">N_VECS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_tweets</span><span class="p">)</span>       <span class="c1"># This many vectors.</span>
<span class="n">N_DIMS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind2Tweet</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>     <span class="c1"># Vector dimensionality.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of vectors is </span><span class="si">{</span><span class="n">N_VECS</span><span class="si">}</span><span class="s2"> and each has </span><span class="si">{</span><span class="n">N_DIMS</span><span class="si">}</span><span class="s2"> dimensions."</span><span class="p">)</span>
<span class="c1"># The number of planes. We use log2(256) to have ~16 vectors/bucket.</span>
<span class="n">N_PLANES</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># Number of times to repeat the hashing to improve the search.</span>
<span class="n">N_UNIVERSES</span> <span class="o">=</span> <span class="mi">25</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of vectors is 10000 and each has 300 dimensions.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Choosing-the-number-of-planes">
<a class="anchor" href="#Choosing-the-number-of-planes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Choosing the number of planes<a class="anchor-link" href="#Choosing-the-number-of-planes"> </a>
</h3>
<ul>
<li>Each plane divides the space to  2  parts.</li>
<li>So  n  planes divide the space into  2n  hash buckets.</li>
<li>We want to organize 10,000 document vectors into buckets so that every bucket has about   16  vectors.</li>
<li>For that we need  10000/16=625  buckets.</li>
<li>We're interested in  n , number of planes, so that  2n=625 . Now, we can calculate  n=log2 625=9.29≈10 .</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Getting-the-hash-number-for-a-vector">
<a class="anchor" href="#Getting-the-hash-number-for-a-vector" aria-hidden="true"><span class="octicon octicon-link"></span></a>Getting the hash number for a vector<a class="anchor-link" href="#Getting-the-hash-number-for-a-vector"> </a>
</h3>
<p>For each vector, we need to get a unique number associated to that vector in order to assign it to a "hash bucket".</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/images/nlp035.png" alt=""></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">planes_l</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N_DIMS</span><span class="p">,</span> <span class="n">N_PLANES</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_UNIVERSES</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">hash_value_of_vector</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">planes</span><span class="p">):</span>
    <span class="sd">"""Create a hash for a vector; hash_id says which random hash to use.</span>
<span class="sd">    Input:</span>
<span class="sd">        - v:  vector of tweet. It's dimension is (1, N_DIMS)</span>
<span class="sd">        - planes: matrix of dimension (N_DIMS, N_PLANES) - the set of planes that divide up the region</span>
<span class="sd">    Output:</span>
<span class="sd">        - res: a number which is used as a hash for your vector</span>

<span class="sd">    """</span>
    <span class="c1"># for the set of planes, calculate the dot product between the vector and the matrix containing the planes</span>
    <span class="c1"># remember that planes has shape (300, 10) The dot product will have the shape (1,10)    </span>
    <span class="n">dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">planes</span><span class="p">)</span>
        
    <span class="c1"># get the sign of the dot product (1,10) shaped vector</span>
    <span class="n">sign_of_dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">dot_product</span> <span class="p">)</span>
      
    <span class="c1"># set h to be false (eqivalent to 0 when used in operations) if the sign is negative,</span>
    <span class="c1"># and true (equivalent to 1) if the sign is positive (1,10) shaped vector</span>
    <span class="c1"># if the sign is 0, i.e. the vector is in the plane, consider the sign to be positive  </span>
    
    <span class="n">h</span><span class="o">=</span> <span class="n">sign_of_dot_product</span> <span class="o">&gt;=</span> <span class="mi">1</span>     
    <span class="c1"># remove extra un-used dimensions (convert this from a 2D to a 1D array)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>       
    <span class="c1"># initialize the hash value to 0</span>
    <span class="n">hash_value</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">n_planes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">planes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_planes</span><span class="p">):</span>
        <span class="c1"># increment the hash value by 2^i * h_i        </span>
        <span class="n">hash_value</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span><span class="o">*</span> <span class="n">h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="c1"># cast hash_value as an integer</span>
    <span class="n">hash_value</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">hash_value</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">hash_value</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">planes</span> <span class="o">=</span> <span class="n">planes_l</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># get one 'universe' of planes to test the function</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" The hash value for this vector,"</span><span class="p">,</span>
      <span class="sa">f</span><span class="s2">"and the set of planes at index </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">,"</span><span class="p">,</span>
      <span class="sa">f</span><span class="s2">"is </span><span class="si">{</span><span class="n">hash_value_of_vector</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> The hash value for this vector, and the set of planes at index 0, is 768
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-a-hash-table">
<a class="anchor" href="#Creating-a-hash-table" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating a hash table<a class="anchor-link" href="#Creating-a-hash-table"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">make_hash_table</span><span class="p">(</span><span class="n">vecs</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">hash_value_of_vector</span><span class="o">=</span><span class="n">hash_value_of_vector</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Input:</span>
<span class="sd">        - vecs: list of vectors to be hashed.</span>
<span class="sd">        - planes: the matrix of planes in a single "universe", with shape (embedding dimensions, number of planes).</span>
<span class="sd">    Output:</span>
<span class="sd">        - hash_table: dictionary - keys are hashes, values are lists of vectors (hash buckets)</span>
<span class="sd">        - id_table: dictionary - keys are hashes, values are list of vectors id's</span>
<span class="sd">                            (it's used to know which tweet corresponds to the hashed vector)</span>
<span class="sd">    """</span>
    <span class="c1"># number of planes is the number of columns in the planes matrix</span>
    <span class="n">num_of_planes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">planes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># number of buckets is 2^(number of planes)    </span>
    <span class="n">num_buckets</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">num_of_planes</span>

    <span class="c1"># create the hash table as a dictionary.</span>
    <span class="c1"># Keys are integers (0,1,2.. number of buckets)</span>
    <span class="c1"># Values are empty lists</span>
    <span class="n">hash_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span> <span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">)}</span>
     
    <span class="c1"># create the id table as a dictionary.</span>
    <span class="c1"># Keys are integers (0,1,2... number of buckets)</span>
    <span class="c1"># Values are empty lists</span>
    <span class="n">id_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span> <span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">)}</span>  
    
    <span class="c1"># for each vector in 'vecs'</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vecs</span><span class="p">):</span>           
        
        <span class="c1"># calculate the hash value for the vector</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">hash_value_of_vector</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>
       
        <span class="c1"># store the vector into hash_table at key h,</span>
        <span class="c1"># by appending the vector v to the list at key h</span>
        <span class="n">hash_table</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        
        <span class="c1"># store the vector's index 'i' (each document is given a unique integer 0,1,2...)</span>
        <span class="c1"># the key is the h, and the 'i' is appended to the list at key h</span>
        <span class="n">id_table</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">hash_table</span><span class="p">,</span> <span class="n">id_table</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">planes</span> <span class="o">=</span> <span class="n">planes_l</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># get one 'universe' of planes to test the function</span>
<span class="n">tmp_hash_table</span><span class="p">,</span> <span class="n">tmp_id_table</span> <span class="o">=</span> <span class="n">make_hash_table</span><span class="p">(</span><span class="n">document_vecs</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The hash table at key 0 has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tmp_hash_table</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2"> document vectors"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The id table at key 0 has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tmp_id_table</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The first 5 document indices stored at key 0 of are </span><span class="si">{</span><span class="n">tmp_id_table</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>The hash table at key 0 has 1351 document vectors
The id table at key 0 has 1351
The first 5 document indices stored at key 0 of are [3, 8, 16, 18, 29]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-all-hash-tables">
<a class="anchor" href="#Creating-all-hash-tables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating all hash tables<a class="anchor-link" href="#Creating-all-hash-tables"> </a>
</h3>
<p>hash your vectors and store them in a hash table that would allow you to quickly look up and search for similar vectors.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_hash_id_tables</span><span class="p">(</span><span class="n">n_universes</span><span class="p">):</span>
    <span class="n">hash_tables</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">id_tables</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">universe_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_universes</span><span class="p">):</span>  <span class="c1"># there are 25 hashes</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'working on hash universe #:'</span><span class="p">,</span> <span class="n">universe_id</span><span class="p">)</span>
        <span class="n">planes</span> <span class="o">=</span> <span class="n">planes_l</span><span class="p">[</span><span class="n">universe_id</span><span class="p">]</span>
        <span class="n">hash_table</span><span class="p">,</span> <span class="n">id_table</span> <span class="o">=</span> <span class="n">make_hash_table</span><span class="p">(</span><span class="n">document_vecs</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>
        <span class="n">hash_tables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hash_table</span><span class="p">)</span>
        <span class="n">id_tables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">id_table</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">hash_tables</span><span class="p">,</span> <span class="n">id_tables</span>

<span class="n">hash_tables</span><span class="p">,</span> <span class="n">id_tables</span> <span class="o">=</span> <span class="n">create_hash_id_tables</span><span class="p">(</span><span class="n">N_UNIVERSES</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>working on hash universe #: 0
working on hash universe #: 1
working on hash universe #: 2
working on hash universe #: 3
working on hash universe #: 4
working on hash universe #: 5
working on hash universe #: 6
working on hash universe #: 7
working on hash universe #: 8
working on hash universe #: 9
working on hash universe #: 10
working on hash universe #: 11
working on hash universe #: 12
working on hash universe #: 13
working on hash universe #: 14
working on hash universe #: 15
working on hash universe #: 16
working on hash universe #: 17
working on hash universe #: 18
working on hash universe #: 19
working on hash universe #: 20
working on hash universe #: 21
working on hash universe #: 22
working on hash universe #: 23
working on hash universe #: 24
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Approximate-K-NN">
<a class="anchor" href="#Approximate-K-NN" aria-hidden="true"><span class="octicon octicon-link"></span></a>Approximate K-NN<a class="anchor-link" href="#Approximate-K-NN"> </a>
</h3>
<p>using locality sensitive hashing, to search for documents that are similar to a given document at the index doc_id</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">approximate_knn</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">planes_l</span><span class="p">,</span> <span class="n">hash_tables</span><span class="p">,</span> <span class="n">id_tables</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_universes_to_use</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">hash_value_of_vector</span><span class="o">=</span><span class="n">hash_value_of_vector</span><span class="p">):</span>
    <span class="sd">"""Search for k-NN using hashes."""</span>
    <span class="c1">#assert num_universes_to_use &lt;= N_UNIVERSES      </span>
    <span class="n">vecs_to_consider_l</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>   <span class="c1"># Vectors that will be checked as possible nearest neighbor </span>
    <span class="n">ids_to_consider_l</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>  <span class="c1"># list of document IDs   </span>
    <span class="n">ids_to_consider_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>  <span class="c1"># create a set for ids to consider, for faster checking if a document ID already exists in the set</span>

    <span class="c1"># loop through the universes of planes</span>
    <span class="k">for</span> <span class="n">universe_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_universes_to_use</span><span class="p">):</span>
        
        <span class="n">planes</span> <span class="o">=</span> <span class="n">planes_l</span><span class="p">[</span><span class="n">universe_id</span><span class="p">]</span> <span class="c1"># get the set of planes from the planes_l list, for this particular universe_id       </span>
        <span class="n">hash_value</span> <span class="o">=</span> <span class="n">hash_value_of_vector</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>  <span class="c1"># get the hash value of the vector for this set of planes        </span>
        <span class="n">hash_table</span> <span class="o">=</span> <span class="n">hash_tables</span><span class="p">[</span><span class="n">universe_id</span><span class="p">]</span>  <span class="c1"># get the hash table for this particular universe_id       </span>
        <span class="n">document_vectors_l</span> <span class="o">=</span> <span class="n">hash_table</span><span class="p">[</span><span class="n">hash_value</span><span class="p">]</span>   <span class="c1"># get the list of document vectors for this hash table, where the key is the hash_value        </span>
        <span class="n">id_table</span> <span class="o">=</span> <span class="n">id_tables</span><span class="p">[</span><span class="n">universe_id</span><span class="p">]</span>  <span class="c1"># get the id_table for this particular universe_id        </span>
        <span class="n">new_ids_to_consider</span> <span class="o">=</span> <span class="n">id_table</span><span class="p">[</span><span class="n">hash_value</span><span class="p">]</span> <span class="c1"># get the subset of documents to consider as nearest neighbors from this id_table dictionary</span>

        <span class="k">if</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">new_ids_to_consider</span><span class="p">:</span>
            <span class="n">new_ids_to_consider</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">doc_id</span><span class="p">)</span>   <span class="c1">#-----</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"removed doc_id </span><span class="si">{</span><span class="n">doc_id</span><span class="si">}</span><span class="s2"> of input vector from new_ids_to_search"</span><span class="p">)</span>

        <span class="c1"># loop through the subset of document vectors to consider</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">new_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">new_ids_to_consider</span><span class="p">):</span>

            <span class="c1"># if the document ID is not yet in the set ids_to_consider...</span>
            <span class="k">if</span> <span class="n">new_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ids_to_consider_set</span><span class="p">:</span>
                <span class="c1"># access document_vectors_l list at index i to get the embedding</span>
                <span class="c1"># then append it to the list of vectors to consider as possible nearest neighbors</span>
                <span class="n">document_vector_at_i</span> <span class="o">=</span> <span class="n">get_document_embedding</span><span class="p">(</span><span class="n">all_tweets</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">en_embeddings_subset</span><span class="p">,</span> <span class="n">process_tweet</span><span class="o">=</span><span class="n">process_tweet</span><span class="p">)</span>        <span class="c1">#-----</span>
                <span class="n">vecs_to_consider_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document_vector_at_i</span><span class="p">)</span>                  <span class="c1">#-----</span>

                <span class="c1"># append the new_id (the index for the document) to the list of ids to consider</span>
                <span class="n">ids_to_consider_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_id</span><span class="p">)</span>

                <span class="c1"># also add the new_id to the set of ids to consider</span>
                <span class="c1"># (use this to check if new_id is not already in the IDs to consider)</span>
                <span class="n">ids_to_consider_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">new_id</span><span class="p">)</span>

    <span class="c1"># Now run k-NN on the smaller set of vecs-to-consider.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Fast considering </span><span class="si">%d</span><span class="s2"> vecs"</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">vecs_to_consider_l</span><span class="p">))</span>

    <span class="c1"># convert the vecs to consider set to a list, then to a numpy array</span>
    <span class="n">vecs_to_consider_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vecs_to_consider_l</span><span class="p">)</span>

    <span class="c1"># call nearest neighbors on the reduced list of candidate vectors</span>
    <span class="n">nearest_neighbor_idx_l</span> <span class="o">=</span> <span class="n">nearest_neighbor</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">vecs_to_consider_arr</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

    <span class="c1"># Use the nearest neighbor index list as indices into the ids to consider</span>
    <span class="c1"># create a list of nearest neighbors by the document ids</span>
    <span class="n">nearest_neighbor_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">ids_to_consider_l</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">nearest_neighbor_idx_l</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">nearest_neighbor_ids</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">doc_id</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">doc_to_search</span> <span class="o">=</span> <span class="n">all_tweets</span><span class="p">[</span><span class="n">doc_id</span><span class="p">]</span>
<span class="n">vec_to_search</span> <span class="o">=</span> <span class="n">document_vecs</span><span class="p">[</span><span class="n">doc_id</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nearest_neighbor_ids</span> <span class="o">=</span> <span class="n">approximate_knn</span><span class="p">(</span>
    <span class="n">doc_id</span><span class="p">,</span> <span class="n">vec_to_search</span><span class="p">,</span> <span class="n">planes_l</span><span class="p">,</span> <span class="n">hash_tables</span><span class="p">,</span> <span class="n">id_tables</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_universes_to_use</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>removed doc_id 5 of input vector from new_ids_to_search
removed doc_id 5 of input vector from new_ids_to_search
removed doc_id 5 of input vector from new_ids_to_search
removed doc_id 5 of input vector from new_ids_to_search
removed doc_id 5 of input vector from new_ids_to_search
Fast considering 150 vecs
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\juan_\AppData\Local\Temp/ipykernel_16868/2362656131.py:15: RuntimeWarning: invalid value encountered in double_scalars
  cos_similarity = np.dot(v,row)/(np.linalg.norm(v)*np.linalg.norm(row))
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Nearest neighbors for document </span><span class="si">{</span><span class="n">doc_id</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Document contents: </span><span class="si">{</span><span class="n">doc_to_search</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>

<span class="k">for</span> <span class="n">neighbor_id</span> <span class="ow">in</span> <span class="n">nearest_neighbor_ids</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Nearest neighbor at document id </span><span class="si">{</span><span class="n">neighbor_id</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"document contents: </span><span class="si">{</span><span class="n">all_tweets</span><span class="p">[</span><span class="n">neighbor_id</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Nearest neighbors for document 5
Document contents: @BhaktisBanter @PallaviRuhail This one is irresistible :)
#FlipkartFashionFriday http://t.co/EbZ0L2VENM

Nearest neighbor at document id 4193
document contents: This girl :)  https://t.co/OAXMGGICNr
Nearest neighbor at document id 4045
document contents: @LemonyLimeUK thanks for the follow have a great day :)
Nearest neighbor at document id 8914
document contents: @zaynmalik zayn come back to 1D already. :(
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="juandrh/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/python/nlp/ml/2022/04/10/1-4-NLP_Machine_Translation_and_Document_Search.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Aprendiendo Inteligencia Artificial a los 50.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/juandrh" target="_blank" title="juandrh"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/juandrh2_0" target="_blank" title="juandrh2_0"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
