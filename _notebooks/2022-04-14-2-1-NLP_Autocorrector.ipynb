{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42599432",
   "metadata": {},
   "source": [
    "# \"1.4- NLP: Autocorrector\"\n",
    "> \"Procesamiento del lenguaje natural con Modelos Probabilísticos\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [python, NLP, ML]\n",
    "- image: images/framework.jpg\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148a1e2",
   "metadata": {},
   "source": [
    "Fuentes:\n",
    "[DeepLearning.AI: Procesamiento de lenguaje natural. Programa especializado en Coursera](https://www.coursera.org/specializations/natural-language-processing) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0bdf3-c7e5-40db-bcf6-9e9d6203e3fd",
   "metadata": {},
   "source": [
    "> tip: Puedes ver este post en GitHub o ejecutarlo en Binder o Google Colab, pulsa el icono."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b95f76",
   "metadata": {},
   "source": [
    "# Construir el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b6057-523d-489c-86b1-accf5a736240",
   "metadata": {},
   "source": [
    "## Creación del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde2752f-e2fb-4571-86f1-a07dc8f89776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re # regular expression library; for tokenization of words\n",
    "from collections import Counter # collections library; counter: dict subclass for counting hashable objects\n",
    "import matplotlib.pyplot as plt # for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1394348-0940-436b-8731-038338df2415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red pink pink blue blue yellow ORANGE BLUE BLUE PINK\n",
      "string length :  52\n"
     ]
    }
   ],
   "source": [
    "# the tiny corpus of text ! \n",
    "text = 'red pink pink blue blue yellow ORANGE BLUE BLUE PINK' # 🌈\n",
    "print(text)\n",
    "print('string length : ',len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ddbdb-3919-47ab-b129-03a728887e20",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63c3fc7-04a0-4ca7-8571-33599fdd5f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red pink pink blue blue yellow orange blue blue pink\n",
      "string length :  52\n"
     ]
    }
   ],
   "source": [
    "# convert all letters to lower case\n",
    "text_lowercase = text.lower()\n",
    "print(text_lowercase)\n",
    "print('string length : ',len(text_lowercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea8119c-4441-44c0-bd23-75fc40523ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red', 'pink', 'pink', 'blue', 'blue', 'yellow', 'orange', 'blue', 'blue', 'pink']\n",
      "count :  10\n"
     ]
    }
   ],
   "source": [
    "# some regex to tokenize the string to words and return them in a list\n",
    "words = re.findall(r'\\w+', text_lowercase)\n",
    "print(words)\n",
    "print('count : ',len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857219e-c71e-42db-b1ce-05f75f484a35",
   "metadata": {},
   "source": [
    "### Creación del vocabulario\n",
    "Un conjunto de palabras distintas del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8d1f18-ea30-4a5f-baab-752b84974799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'red', 'blue', 'pink', 'orange', 'yellow'}\n",
      "count :  5\n"
     ]
    }
   ],
   "source": [
    "# create vocab\n",
    "vocab = set(words)\n",
    "print(vocab)\n",
    "print('count : ',len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385593e-4aca-4500-9d97-5815da144689",
   "metadata": {},
   "source": [
    "### Agregar información con el conteo de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f4b7e86-4101-45ac-b6b6-6d948a1a84ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'red': 1, 'pink': 3, 'blue': 4, 'yellow': 1, 'orange': 1}\n",
      "count :  5\n"
     ]
    }
   ],
   "source": [
    "# Opción 1: crear vocabulario incluyendo el conteo de palabras\n",
    "counts_a = dict()\n",
    "for w in words:\n",
    "    counts_a[w] = counts_a.get(w,0)+1\n",
    "print(counts_a)\n",
    "print('count : ',len(counts_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0a3299-710f-4301-b709-88c0f7078809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'blue': 4, 'pink': 3, 'red': 1, 'yellow': 1, 'orange': 1})\n",
      "count :  5\n"
     ]
    }
   ],
   "source": [
    "# Opción 2: crear vocabulario usando collections.Counter\n",
    "counts_b = dict()\n",
    "counts_b = Counter(words)\n",
    "print(counts_b)\n",
    "print('count : ',len(counts_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb09365-bc42-4572-8acc-8d25048ddaeb",
   "metadata": {},
   "source": [
    "## Identificar una palabra mal escrita\n",
    "Se puede comporbar si está en el vocabulario. Si no lo está puede ser un candidato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db0aeb-7620-456f-b091-e82447691e68",
   "metadata": {},
   "source": [
    "## Encontrar cadenas que están a n distancia de editar\n",
    "Estas podrían ser cadenas aleatorias.\n",
    "\n",
    "Editar: operación en una cadena para cambiarla.\n",
    "\n",
    "- Operaciones:\n",
    "  - Insertar: añadir una letra\n",
    "  - Borrar: eleminar una letra\n",
    "  - Cambiar: intercambiar dos letras seguidas\n",
    "  - Sustituir: cambiar una letra por otra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d8d67c-d451-4728-b050-2b40f1751bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "word = 'dearz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0dbf2-8e69-4a90-977b-2f4ab346d6cf",
   "metadata": {},
   "source": [
    "### Divisiones\n",
    "Encontrar todas las formas en que se puede dividir la palabra en 2 partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d335b5a6-878b-492b-ba09-7391fcd96222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'dearz']\n",
      "['d', 'earz']\n",
      "['de', 'arz']\n",
      "['dea', 'rz']\n",
      "['dear', 'z']\n",
      "['dearz', '']\n"
     ]
    }
   ],
   "source": [
    "# Opción 1: con un bucle\n",
    "splits_a = []\n",
    "for i in range(len(word)+1):\n",
    "    splits_a.append([word[:i],word[i:]])\n",
    "\n",
    "for i in splits_a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "252e9cd5-ea7c-4678-9225-2e71aa6a2e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'dearz')\n",
      "('d', 'earz')\n",
      "('de', 'arz')\n",
      "('dea', 'rz')\n",
      "('dear', 'z')\n",
      "('dearz', '')\n"
     ]
    }
   ],
   "source": [
    "# Opción 2: con list comprehension\n",
    "splits_b = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "\n",
    "for i in splits_b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20700ed-469f-4c3a-b9d7-bb915699fe2a",
   "metadata": {},
   "source": [
    "### Operación borrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670e821c-6725-4b25-a32d-15b99d81e45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word :  dearz\n",
      "earz  <-- delete  d\n",
      "darz  <-- delete  e\n",
      "derz  <-- delete  a\n",
      "deaz  <-- delete  r\n",
      "dear  <-- delete  z\n"
     ]
    }
   ],
   "source": [
    "# Opción 1: con un bucle\n",
    "splits = splits_a\n",
    "deletes = []\n",
    "\n",
    "print('word : ', word)\n",
    "for L,R in splits:\n",
    "    if R:\n",
    "        print(L + R[1:], ' <-- delete ', R[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e21652ce-9869-403c-be00-ff8a853517a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['earz', 'darz', 'derz', 'deaz', 'dear']\n",
      "*** which is the same as ***\n",
      "earz\n",
      "darz\n",
      "derz\n",
      "deaz\n",
      "dear\n"
     ]
    }
   ],
   "source": [
    "# Opción 2: con list comprehension\n",
    "splits = splits_a\n",
    "deletes = [L + R[1:] for L, R in splits if R]\n",
    "\n",
    "print(deletes)\n",
    "print('*** which is the same as ***')\n",
    "for i in deletes:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f862977-5fb7-4f9f-b3fe-9774688fb702",
   "metadata": {},
   "source": [
    "## Filtrar candidatos\n",
    "Mantener solo las palabras reales de los pasos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc917eed-75a0-4ab9-a36b-62028feb4eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab :  ['dean', 'deer', 'dear', 'fries', 'and', 'coke']\n",
      "edits :  ['earz', 'darz', 'derz', 'deaz', 'dear']\n",
      "candidate words :  {'dear'}\n"
     ]
    }
   ],
   "source": [
    "vocab = ['dean','deer','dear','fries','and','coke']\n",
    "edits = list(deletes)\n",
    "\n",
    "print('vocab : ', vocab)\n",
    "print('edits : ', edits)\n",
    "\n",
    "candidates=[]\n",
    "candidates = set(edits).intersection(vocab)  # hint: 'set.intersection'\n",
    "\n",
    "\n",
    "print('candidate words : ', candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f85ba-4ed4-4dea-9d94-c46e644b2ba5",
   "metadata": {},
   "source": [
    "## Calcular probabilidades de palabras\n",
    "Elegir la palabra que es más probable que ocurra en ese contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281a26e9-595b-44dc-950c-25b1e5a86067",
   "metadata": {},
   "source": [
    "![](images/nlp036.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b3a37-040b-4a99-b1b5-0ba5ae797f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
