{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42599432",
   "metadata": {},
   "source": [
    "# \"1.4- NLP: Autocorrector\"\n",
    "> \"Procesamiento del lenguaje natural con Modelos Probabilísticos\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [python, NLP, ML]\n",
    "- image: images/framework.jpg\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148a1e2",
   "metadata": {},
   "source": [
    "Fuentes:\n",
    "\n",
    "\n",
    "[DeepLearning.AI: Procesamiento de lenguaje natural. Programa especializado en Coursera](https://www.coursera.org/specializations/natural-language-processing) \n",
    "\n",
    "\n",
    "[How to Write a Spelling Corrector, Peter Norvig, 2007](https://norvig.com/spell-correct.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0bdf3-c7e5-40db-bcf6-9e9d6203e3fd",
   "metadata": {},
   "source": [
    "> tip: Puedes ver este post en GitHub o ejecutarlo en Binder o Google Colab, pulsa el icono."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b95f76",
   "metadata": {},
   "source": [
    "# Construir el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b6057-523d-489c-86b1-accf5a736240",
   "metadata": {},
   "source": [
    "## Creación del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fde2752f-e2fb-4571-86f1-a07dc8f89776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re # regular expression library; for tokenization of words\n",
    "from collections import Counter # collections library; counter: dict subclass for counting hashable objects\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1394348-0940-436b-8731-038338df2415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red pink pink blue blue yellow ORANGE BLUE BLUE PINK\n",
      "string length :  52\n"
     ]
    }
   ],
   "source": [
    "# the tiny corpus of text ! \n",
    "text = 'red pink pink blue blue yellow ORANGE BLUE BLUE PINK' # 🌈\n",
    "print(text)\n",
    "print('string length : ',len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ddbdb-3919-47ab-b129-03a728887e20",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c0afb4c-c2c5-4019-b34f-8edfb072a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file_name which is found in your current directory. You just have to read it in. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus (text file you read) in lower case. \n",
    "    \"\"\"\n",
    "    words = [] # return this variable correctly\n",
    "   \n",
    "    #Open the file, read its contents into a string variable\n",
    "    with open(file_name, 'r') as file:\n",
    "        text = file.read()\n",
    "    # convert all letters to lower case\n",
    "    text_lowercase = text.lower()\n",
    "    #Convert every word to lower case and return them in a list.\n",
    "    words = re.findall(r'\\w+', text_lowercase)\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b558a9a3-2f11-4250-a52c-62c3c996e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
      "There are 6116 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "word_l = process_data('./data/shakespeare.txt')\n",
    "vocab = set(word_l)  # this will be your new vocabulary\n",
    "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857219e-c71e-42db-b1ce-05f75f484a35",
   "metadata": {},
   "source": [
    "### Creación del vocabulario\n",
    "Un conjunto de palabras distintas del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8d1f18-ea30-4a5f-baab-752b84974799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'red', 'blue', 'pink', 'orange', 'yellow'}\n",
      "count :  5\n"
     ]
    }
   ],
   "source": [
    "# create vocab\n",
    "vocab = set(words)\n",
    "print(vocab)\n",
    "print('count : ',len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385593e-4aca-4500-9d97-5815da144689",
   "metadata": {},
   "source": [
    "### Agregar información con el conteo de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f4b7e86-4101-45ac-b6b6-6d948a1a84ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'red': 1, 'pink': 3, 'blue': 4, 'yellow': 1, 'orange': 1}\n",
      "count :  5\n"
     ]
    }
   ],
   "source": [
    "# Opción 1: crear vocabulario incluyendo el conteo de palabras\n",
    "counts_a = dict()\n",
    "for w in words:\n",
    "    counts_a[w] = counts_a.get(w,0)+1\n",
    "print(counts_a)\n",
    "print('count : ',len(counts_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0a3299-710f-4301-b709-88c0f7078809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'blue': 4, 'pink': 3, 'red': 1, 'yellow': 1, 'orange': 1})\n",
      "count :  5\n"
     ]
    }
   ],
   "source": [
    "# Opción 2: crear vocabulario usando collections.Counter\n",
    "counts_b = dict()\n",
    "counts_b = Counter(words)\n",
    "print(counts_b)\n",
    "print('count : ',len(counts_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45c5a575-3639-40d8-8d7e-8264f09aec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word_l):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''\n",
    "    word_count_dict = {}  # fill this with word counts\n",
    "    word_count_dict = Counter(word_l)   \n",
    "\n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3b4e697-4ac4-49e1-a3b6-e01c03a1ee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 key values pairs\n",
      "The count for the word 'thee' is 240\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = get_count(word_l)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb09365-bc42-4572-8acc-8d25048ddaeb",
   "metadata": {},
   "source": [
    "## Identificar una palabra mal escrita\n",
    "Se puede comporbar si está en el vocabulario. Si no lo está puede ser un candidato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db0aeb-7620-456f-b091-e82447691e68",
   "metadata": {},
   "source": [
    "## Encontrar cadenas que están a n ediciones de distancia\n",
    "Estas podrían ser cadenas aleatorias.\n",
    "\n",
    "Editar: operación en una cadena para cambiarla.\n",
    "\n",
    "- Operaciones:\n",
    "  - Insertar: añadir una letra\n",
    "  - Borrar: eleminar una letra\n",
    "  - Cambiar: intercambiar dos letras seguidas\n",
    "  - Sustituir: cambiar una letra por otra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d8d67c-d451-4728-b050-2b40f1751bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "word = 'dearz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0dbf2-8e69-4a90-977b-2f4ab346d6cf",
   "metadata": {},
   "source": [
    "### Divisiones\n",
    "Encontrar todas las formas en que se puede dividir la palabra en 2 partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d335b5a6-878b-492b-ba09-7391fcd96222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'dearz']\n",
      "['d', 'earz']\n",
      "['de', 'arz']\n",
      "['dea', 'rz']\n",
      "['dear', 'z']\n",
      "['dearz', '']\n"
     ]
    }
   ],
   "source": [
    "# Opción 1: con un bucle\n",
    "splits_a = []\n",
    "for i in range(len(word)+1):\n",
    "    splits_a.append([word[:i],word[i:]])\n",
    "\n",
    "for i in splits_a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "252e9cd5-ea7c-4678-9225-2e71aa6a2e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'dearz')\n",
      "('d', 'earz')\n",
      "('de', 'arz')\n",
      "('dea', 'rz')\n",
      "('dear', 'z')\n",
      "('dearz', '')\n"
     ]
    }
   ],
   "source": [
    "# Opción 2: con list comprehension\n",
    "splits_b = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "\n",
    "for i in splits_b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20700ed-469f-4c3a-b9d7-bb915699fe2a",
   "metadata": {},
   "source": [
    "### Operación borrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670e821c-6725-4b25-a32d-15b99d81e45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word :  dearz\n",
      "earz  <-- delete  d\n",
      "darz  <-- delete  e\n",
      "derz  <-- delete  a\n",
      "deaz  <-- delete  r\n",
      "dear  <-- delete  z\n"
     ]
    }
   ],
   "source": [
    "# Opción 1: con un bucle\n",
    "splits = splits_a\n",
    "deletes = []\n",
    "\n",
    "print('word : ', word)\n",
    "for L,R in splits:\n",
    "    if R:\n",
    "        print(L + R[1:], ' <-- delete ', R[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e21652ce-9869-403c-be00-ff8a853517a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['earz', 'darz', 'derz', 'deaz', 'dear']\n",
      "*** which is the same as ***\n",
      "earz\n",
      "darz\n",
      "derz\n",
      "deaz\n",
      "dear\n"
     ]
    }
   ],
   "source": [
    "# Opción 2: con list comprehension\n",
    "splits = splits_a\n",
    "deletes = [L + R[1:] for L, R in splits if R]\n",
    "\n",
    "print(deletes)\n",
    "print('*** which is the same as ***')\n",
    "for i in deletes:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0e0ea08-dc41-450c-a541-b52b453db2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    split_l = [ (word[:i],word[i:]) for i in range(len(word))]\n",
    "    delete_l= [ L+R[1:] for L,R in split_l if R]\n",
    "\n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return  delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4140805-f11c-41e2-a437-aecb2a272900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word Soleado, \n",
      "split_l = [('', 'Soleado'), ('S', 'oleado'), ('So', 'leado'), ('Sol', 'eado'), ('Sole', 'ado'), ('Solea', 'do'), ('Solead', 'o')], \n",
      "delete_l = ['oleado', 'Sleado', 'Soeado', 'Solado', 'Soledo', 'Soleao', 'Solead']\n"
     ]
    }
   ],
   "source": [
    "delete_word_l = delete_letter(word=\"Soleado\",\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1dedd-4667-4582-817d-7d9e987be2c6",
   "metadata": {},
   "source": [
    "### Operación cambiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab678ffe-3a40-4ed3-8772-5415f24052c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    split_l = [ (word[:i],word[i:]) for i in range(len(word))]\n",
    "    switch_l = [ L+R[:2][::-1]+R[2:] for L,R in split_l if len(R)>1]\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "    \n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27b8103c-51f3-41e1-ac6e-4a712685e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = soleado \n",
      "split_l = [('', 'soleado'), ('s', 'oleado'), ('so', 'leado'), ('sol', 'eado'), ('sole', 'ado'), ('solea', 'do'), ('solead', 'o')] \n",
      "switch_l = ['osleado', 'sloeado', 'soelado', 'solaedo', 'soledao', 'soleaod']\n"
     ]
    }
   ],
   "source": [
    "switch_word_l = switch_letter(word=\"soleado\",\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458c003-a0c4-469d-a9c3-4f9f1750d03b",
   "metadata": {},
   "source": [
    "### Operación sustituir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "034012ab-3d45-48f2-88a1-19000f513a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    split_l = [ (word[:i],word[i:]) for i in range(len(word))]\n",
    "    replace_l = [L+c+R[1:] for L,R in split_l if len(R)>0 for c in letters]\n",
    "    replace_set=set(replace_l)\n",
    "    replace_set.discard(word)\n",
    "   \n",
    "    # turn the set back into a list and sort it, for easier viewing\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "edfdb2b7-4f76-4036-9a50-261f645f371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = can \n",
      "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
      "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
     ]
    }
   ],
   "source": [
    "replace_l = replace_letter(word='can',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17a951-f0af-405a-9d58-a4b5c58456fd",
   "metadata": {},
   "source": [
    "### Operación insertar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97229fdb-bd3f-43f3-97cd-54c75f658690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    split_l = [ (word[:i],word[i:]) for i in range(len(word)+1)]  \n",
    "    insert_l = [L+c+R for L,R in split_l if len(R)>-1 for c in letters]\n",
    "    \n",
    "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    \n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f58ce57-2501-4308-84db-266a13e0b096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word at \n",
      "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
      "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
      "Number of strings output by insert_letter('at') is 78\n"
     ]
    }
   ],
   "source": [
    "insert_l = insert_letter('at', True)\n",
    "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60882f-4913-4374-81c4-2aebbc69dec7",
   "metadata": {},
   "source": [
    "### Función editar una letra\n",
    "Para obtener todas las ediciones posibles que están a una edición de distancia de una palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1bf18bae-0b8b-4921-9c43-d6bec2ceb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"   \n",
    "    edit_one_set = set()\n",
    "    edit_one_set = delete_letter(word)+ replace_letter(word)+insert_letter(word)\n",
    "    \n",
    "    if allow_switches:\n",
    "        edit_one_set += switch_letter(word)    \n",
    "\n",
    "    return set(edit_one_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38b3dae4-71ec-420c-8738-1d60bdf83f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word at \n",
      "edit_one_l \n",
      "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
      "\n",
      "The type of the returned object should be a set <class 'set'>\n",
      "Number of outputs from edit_one_letter('at') is 129\n"
     ]
    }
   ],
   "source": [
    "tmp_word = \"at\"\n",
    "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
    "# turn this into a list to sort it, in order to view it\n",
    "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
    "\n",
    "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
    "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
    "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847bf91c-e537-457a-aacb-7c849a673824",
   "metadata": {},
   "source": [
    "### Función editar dos letras\n",
    "Para obtener todas las ediciones posibles que están a dos ediciones de distancia de una palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00914217-5cca-4d15-ba5e-cb2f5e55312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    for w in edit_one_letter(word,allow_switches):\n",
    "        edit_two_set.update(edit_one_letter(w,allow_switches))  \n",
    "   \n",
    "    # return this as a set instead of a list\n",
    "    return set(edit_two_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f28c3d8-049c-4688-8448-2a2a46c5abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings with edit distance of two: 2654\n",
      "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
      "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
      "The data type of the returned object should be a set <class 'set'>\n",
      "Number of strings that are 2 edit distances from 'at' is 7154\n"
     ]
    }
   ],
   "source": [
    "tmp_edit_two_set = edit_two_letters(\"a\")\n",
    "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
    "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
    "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
    "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
    "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
    "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f862977-5fb7-4f9f-b3fe-9774688fb702",
   "metadata": {},
   "source": [
    "## Filtrar candidatos\n",
    "Mantener solo las palabras reales de los pasos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc917eed-75a0-4ab9-a36b-62028feb4eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab :  ['dean', 'deer', 'dear', 'fries', 'and', 'coke']\n",
      "edits :  ['earz', 'darz', 'derz', 'deaz', 'dear']\n",
      "candidate words :  {'dear'}\n"
     ]
    }
   ],
   "source": [
    "vocab = ['dean','deer','dear','fries','and','coke']\n",
    "edits = list(deletes)\n",
    "\n",
    "print('vocab : ', vocab)\n",
    "print('edits : ', edits)\n",
    "\n",
    "candidates=[]\n",
    "candidates = set(edits).intersection(vocab)  # hint: 'set.intersection'\n",
    "\n",
    "\n",
    "print('candidate words : ', candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f85ba-4ed4-4dea-9d94-c46e644b2ba5",
   "metadata": {},
   "source": [
    "## Calcular probabilidades de palabras\n",
    "Elegir la palabra que es más probable que ocurra en ese contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281a26e9-595b-44dc-950c-25b1e5a86067",
   "metadata": {},
   "source": [
    "![](images/nlp036.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d85be91-c73e-4fbd-b8fe-b1779246e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}  # return this variable correctly\n",
    "    \n",
    "    # get the total count of words for all words in the dictionary\n",
    "    M = sum(word_count_dict.values())    \n",
    "    \n",
    "    #for k in word_count_dict:\n",
    "     #   probs[k]=word_count_dict[k]/M\n",
    "    \n",
    "    probs = { k:(v/M) for (k,v) in word_count_dict.items()}\n",
    "    \n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71aef13e-8d1c-4bd3-9599-26af7c92c563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 6116\n",
      "P('thee') is 0.0045\n"
     ]
    }
   ],
   "source": [
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('thee') is {probs['thee']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c3a6f-67b1-4e96-96d0-9a5d8d73a41f",
   "metadata": {},
   "source": [
    "## Distancia mínima de edición\n",
    "\n",
    "Permite:\n",
    "\n",
    "- Evaluar la similitud entre dos cadenas\n",
    "- Encontrar el número mínimo de ediciones entre dos cadenas\n",
    "- Implementar un corrección ortográfica, similitud de documentos, traducción automática, secuenciación de ADN y más\n",
    "\n",
    "Coste = distancia de edición entre dos cadenas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd962b0-b2ed-47bf-b0ab-09c131544b51",
   "metadata": {},
   "source": [
    "![](images/nlp037.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5b0ab-afd3-4cb7-8ef5-bcb43827f3d0",
   "metadata": {},
   "source": [
    "### Algoritmo de distancia mínima de edición\n",
    "Se comienza con una palabra de origen y la transforma en la palabra de destino. \n",
    "\n",
    "Para pasar de # -> #  se necesita un costo de 0.\n",
    "De p -> # se necesita un costo de 1, costo de una eliminación.\n",
    "De p -> s es 2,  costo mínimo que uno podría usar para llegar de p a s.\n",
    "\n",
    "Seguir así completando un elemento a la vez. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5302c-4baa-4f7b-9f92-96e1943bc034",
   "metadata": {},
   "source": [
    "![](images/nlp038.png)\n",
    "![](images/nlp039.png)\n",
    "![](images/nlp040.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa53711-4ad2-4cdc-8003-39940b982c98",
   "metadata": {},
   "source": [
    "Esta es la distancia de Levenshtein que especifica el costo por operación.\n",
    "Si se necesita reconstruir la ruta de cómo llegó de una cadena a la otra, puede usar el camino inverso.\n",
    "\n",
    "Esta es la técnica de **Programación dinámica**:  Primero resuelve el subproblema más pequeño primero y luego, reutilizando ese resultado, resuelve el siguiente subproblema más grande, guardando ese resultado, reutilizándolo nuevamente, y así sucesivamente. Esto es exactamente lo que hizo al completar cada celda desde la esquina superior derecha hasta la esquina inferior izquierda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348f603-2bb1-453d-84c4-2a8902969d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
