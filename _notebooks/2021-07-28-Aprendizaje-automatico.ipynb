{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295aab91",
   "metadata": {},
   "source": [
    "# \"Proceso de aprendizaje automático supervisado\"\n",
    "> \"Una introducción la automatización del aprendizaje supervisado. Python + Pytorch\"\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [curso_Fast.ai,ML]\n",
    "- image: images/logo.png\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615de072",
   "metadata": {},
   "source": [
    "# Proceso de aprendizaje automático supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de3640",
   "metadata": {},
   "source": [
    "Partimos de una **realidad** que queremos estudiar. <br>\n",
    "Buscando **patrones** construimos **modelos** que simplifiquen esta realidad y nos ayuden a sacar ventajas.<br>\n",
    "Los modelos buscan el equilibrio entre representar bien la realidad y la simplicidad de uso.<br>\n",
    "\n",
    "Elementos:\n",
    "\n",
    "- datos: valores sacados de la realidad que alimentan el modelo\n",
    "- parámetros: valores que se pueden variar para ajustar el modelo\n",
    "- error: mide el grado de ajuste de nuestro modelo a los datos\n",
    "\n",
    "Partiendo de un modelo inicial, el objetivo será **optimizar**lo (entrenarlo, ajustarlo) a través de la variación de los parámetros buscando el mínimo error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b28fc",
   "metadata": {},
   "source": [
    "## El modelo: Regresión lineal como primer acercamiento "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc7c6e",
   "metadata": {},
   "source": [
    "Dentro del *aprendizaje automático* (machine learning) hay tres ramas diferenciadas:\n",
    "\n",
    "   - **aprendizaje supervisado**: se tiene datos etiquetados (clasificados), sabemos el objetivo buscado\n",
    "   - **aprendizaje no supervisado**: se busca sacar conocimiento con datos no etiquetados, se desconoce a priori el objetivo. \n",
    "   - **aprendizaje reforzado**: se establece un sistema de refuerzos y penalizaciones para llegar al objetivo\n",
    "\n",
    "Nosotros comenzaremos por el aprendizaje supervisado escogiendo lo más sencillo, un modelo lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61cd9a",
   "metadata": {},
   "source": [
    "#### Regresión lineal simple: una variable\n",
    "\n",
    "Tenemos sólo una variable **x** de entrada (v. independiente), y se busca un resultado **y** que depende de la anterior. Existe una relación lineal entre ambas, por lo que se representa como una línea:\n",
    "\n",
    "y = b + w1 * x\n",
    "\n",
    "b y w1 son los parámetros: el sesgo y la pendiente de la línea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59043c2e",
   "metadata": {},
   "source": [
    "![](images/linea.png \"y = b + w1 * x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58efb91",
   "metadata": {},
   "source": [
    "#### Regresión lineal múltiple\n",
    "\n",
    "##### 2 variables\n",
    "\n",
    "Representan un plano\n",
    "\n",
    "y = b + w1 * x1 + w2 * x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbab7f7",
   "metadata": {},
   "source": [
    "![](images/plano.png \"y = b + w1 * x1 + w2 * x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff4f46",
   "metadata": {},
   "source": [
    "##### n variables\n",
    "\n",
    "Representan un hiperplano\n",
    "\n",
    "y = b + w1 * x1 + w2 * x2 + w3 * x3 + ... + wn* xn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b4532",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Tanto para regresion lineal simple como múltiple tendremos unos datos sacados de la realidad y queremos encontrar un modelo (una línea, plano,...) que se aproxime a ellos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93346aa6",
   "metadata": {},
   "source": [
    "![](images/estimacion01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330c65c",
   "metadata": {},
   "source": [
    "Para cada punto podemos calcular el error (distancia) que hay entre el valor real y la predicción:<br>\n",
    "<br>\n",
    "error = Y real - Y estimado\n",
    "<br><br>\n",
    "El **error** (coste) **del modelo** será la media de estas distancias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_media_abs = ((y_real-y_estimado)).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93067147",
   "metadata": {},
   "source": [
    "![](images/estimacion02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac18b57",
   "metadata": {},
   "source": [
    "Aunque, se suele utilizar la raiz cuadrada del **error medio cuadrático (MSE)** porque penaliza más cuanto mayor sea el error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mse = ((y_real-y_estimado)**2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaed002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En Pytorch tenemos estas funciones ya optimizadas\n",
    "F.l1_loss(y_real.float(),y_estimado)\n",
    "F.mse_loss(y_real,y_estimado).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56da44",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e246b",
   "metadata": {},
   "source": [
    "## El aprendizaje: Descenso del gradiente "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613353a8",
   "metadata": {},
   "source": [
    "Una vez tenemos el modelo y la función de error, iremos dando valores a los parámetros **w y b** buscando el menor error hasta encontrar el modelo que mejor se ajuste a la realidad.\n",
    "\n",
    "Queremos que ese ajuste de parámetros se realice de forma autónoma. Para ello tenemos la herramienta **desceso del gradiente**. \n",
    "\n",
    "La técnica de *descenso del gradiente* consiste en moverse por la función de error buscando el punto donde se minimiza. Para ello, en cada posición, busca la dirección en la que se reduce más el error. Esto se obtiene con la derivada parcial en el punto respecto de cáda parámetro (el gradiente de la función), que es la pendiente de la curva.\n",
    "\n",
    "Una vez obtenida la dirección en que hay que moverse se recalculan los parámetros de la siguiente forma:\n",
    "\n",
    "w := w - gradiente(w) * lr\n",
    "\n",
    "\n",
    "'lr' es la **tasa de aprendizaje**, que define el tamaño del paso que se realizará. Si es demasiado pequeño se necesitará mucho tiempo para alcanzar el mínimo y si es muy grande seguramente se pasará de largo sin llegar al mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab35150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En Pytorch la siguiente función calcula el gradiente\n",
    "funcion_error.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e07efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra el gradiente calculado\n",
    "parametros.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b070a3c4",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Ahora ya podemos preparar el algoritmo de aprendizaje automático. Los pasos serán:\n",
    "\n",
    "    1- Cargar los datos y escoger el modelo\n",
    "    2- Inicializar los parámetros: se suele hacer de forma aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los parámetros (w) pueden almacenar el gradiente con \"requires_grad_()\" \n",
    "parametros = torch.randn(num_parametros).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf78d0",
   "metadata": {},
   "source": [
    "    3- Calcular la predicciones\n",
    "    4- Calcular el error (coste)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4776844",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = mse(prediciones, valores_reales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee83151",
   "metadata": {},
   "source": [
    "    5- Calcular el gradiente\n",
    "    6- Realizar el paso, modificación de los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ef5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "parametros.data -= lr * parametros.grad.data\n",
    "parametros.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1501f62",
   "metadata": {},
   "source": [
    "    7- Repetir el proceso (punto 3) las veces necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d30c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
